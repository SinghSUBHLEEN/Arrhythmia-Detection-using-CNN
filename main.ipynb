{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3b7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv1D\n",
    "import wfdb                            # Package for loading the ecg and annotation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import random\n",
    "from scipy import signal\n",
    "import pywt\n",
    "import biosppy\n",
    "\n",
    "# Random Initialization\n",
    "random.seed(42)\n",
    "\n",
    "record_list = ['100','101','102','103','104','105','106','107',\n",
    "           '108','109','111','112','113','114','115',\n",
    "           '117','118','119','121','122','123','124','200',\n",
    "           '201','202','203','205','207','208','209','210',\n",
    "           '212','213','214','215','217','219','220','221',\n",
    "           '222','223','228','230','231','232','233','234']\n",
    "\n",
    "path = \"data/\"\n",
    "\n",
    "nonbeat_symbols = ['[','!',']','x','(',')','p','t','u','`',\n",
    "           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n",
    "\n",
    "abnormal = ['L','R','V','/','A','f','F','j','a','E','J','e','S']\n",
    "\n",
    "normal = ['N']\n",
    "\n",
    "num_sec = 3\n",
    "fs = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c9b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bandpassFilter(data):\n",
    "    nyq = 0.5 * 500\n",
    "    low = 3 / nyq\n",
    "    high = 12 / nyq\n",
    "    b, a = signal.butter(3, [low, high], btype='band')\n",
    "    filtered_data = signal.filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "def get_ecg(filename):\n",
    "    signal = wfdb.rdrecord(filename, channels=[0]).p_signal\n",
    "    annotation_symbols = wfdb.rdann(filename, \"atr\").symbol\n",
    "    annotation_symbol_location = wfdb.rdann(filename, \"atr\").sample\n",
    "    \n",
    "    return signal, annotation_symbols, annotation_symbol_location\n",
    "\n",
    "def pan_tompkins(ecg_data, fs=500, rel_amplitude=0.5, min_rr=120, max_rr=200):\n",
    "    diff_data = np.diff(ecg_data)\n",
    "    squared_data = diff_data**2\n",
    "    window_size = int(0.02 * fs)\n",
    "    average_data = np.convolve(squared_data, np.ones(window_size) / window_size, mode='same')\n",
    "    high_threshold = rel_amplitude * np.max(average_data)\n",
    "    low_threshold = 0.5 * high_threshold\n",
    "    peaks = []\n",
    "    for i in range(len(ecg_data)):\n",
    "        if average_data[i] > high_threshold:\n",
    "            peaks.append(i)\n",
    "        if len(peaks) > 1 and i - peaks[-2] < min_rr:\n",
    "            peaks.pop()\n",
    "        elif len(peaks) > 2 and i - peaks[-1] > max_rr:\n",
    "            peaks.pop()\n",
    "\n",
    "    return np.array(peaks)\n",
    "\n",
    "def preProcessing(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = np.fromfile(file, dtype='int16')\n",
    "\n",
    "  #correcting the baseline of the data\n",
    "\n",
    "    corrected_data = signal.detrend(data)\n",
    "\n",
    "  # creating a butter-worth filter or 2nd order\n",
    "  # these are the best frequencie for this data\n",
    "\n",
    "    cutoff_freq = 10\n",
    "    sample_freq = 360 #Hz\n",
    "\n",
    "    b, a = signal.butter(2, cutoff_freq / (sample_freq / 2))\n",
    "\n",
    "  #filtering the signal\n",
    "\n",
    "    filtered_data = signal.filtfilt(b, a, corrected_data)\n",
    "\n",
    "  # applying wavelet transform on the baseline corrected data and then ignoring the high frequency and low frequency components\n",
    "\n",
    "    arr = pywt.wavedec(corrected_data, 'sym4', level=4)\n",
    "\n",
    "  # arr[0] = np.zeros_like(arr[0])\n",
    "    arr[1] = np.zeros_like(arr[1])\n",
    "  # arr[2] = np.zeros_like(arr[2])\n",
    "  # arr[3] = np.zeros_like(arr[3])\n",
    "    arr[4] = np.zeros_like(arr[4])\n",
    "\n",
    "    wavdec_filtered_signal = pywt.waverec(arr, 'sym4')\n",
    "\n",
    "    final_signal = bandpassFilter(wavdec_filtered_signal)\n",
    "\n",
    "\n",
    "    results = biosppy.signals.ecg.christov_segmenter(signal=final_signal, sampling_rate=500)\n",
    "\n",
    "    r_peaks = results['rpeaks']\n",
    "\n",
    "  # return [final_signal, r_peaks]\n",
    "    return r_peaks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c76cbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One complete signal consists of annotation and data. Each annotation file can be divided into two groups whcih\n",
    "# are symbols represting the peaks, like N, A, etc and the location of these symbols in the ecg data from \n",
    "# annotation objects's sample part\n",
    "\n",
    "def get_ecg_(filename):\n",
    "    signal = wfdb.rdrecord(filename, channels=[0]).p_signal\n",
    "    annotation_symbols = wfdb.rdann(filename, \"atr\").symbol\n",
    "    annotation_symbol_location = preProcessing(filename+\".dat\")\n",
    "    \n",
    "    return signal, annotation_symbols, annotation_symbol_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ad0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_XY(p_signal, df_ann, num_cols):\n",
    "    # this function builds the X,Y matrices for each beat\n",
    "    # it also returns the original symbols for Y\n",
    "    \n",
    "    num_rows = len(df_ann)\n",
    "\n",
    "    X = np.zeros((num_rows, num_cols))\n",
    "    Y = np.zeros((num_rows,1))\n",
    "    sym = []\n",
    "    \n",
    "    # keep track of rows\n",
    "    max_row = 0\n",
    "\n",
    "    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n",
    "\n",
    "        left = max([0,(atr_sample  - num_sec*fs) ])\n",
    "        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n",
    "        x = p_signal[left: right]\n",
    "        if len(x) == num_cols:\n",
    "            X[max_row] = x\n",
    "            Y[max_row] = int(atr_sym in abnormal)\n",
    "            sym.append(atr_sym)\n",
    "            max_row += 1\n",
    "    X = X[:max_row,:]\n",
    "    Y = Y[:max_row,:]\n",
    "    return X,Y,sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911657c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(pts, num_sec, fs):\n",
    "    # function for making dataset ignoring non-beats\n",
    "    # input:\n",
    "    #   pts - list of patients\n",
    "    #   num_sec = number of seconds to include before and after the beat\n",
    "    #   fs = frequency\n",
    "    # output: \n",
    "    #   X_all = signal (nbeats , num_sec * fs columns)\n",
    "    #   Y_all = binary is abnormal (nbeats, 1)\n",
    "    #   sym_all = beat annotation symbol (nbeats,1)\n",
    "    \n",
    "    # initialize numpy arrays\n",
    "    num_cols = 2*num_sec*fs\n",
    "    X_all = np.zeros((1,num_cols))\n",
    "    Y_all = np.zeros((1,1))\n",
    "    sym_all = []\n",
    "    \n",
    "    # list to keep track of number of beats across patients\n",
    "    max_rows = []\n",
    "    \n",
    "    for pt in pts:\n",
    "        file = path + pt\n",
    "        \n",
    "        p_signal, atr_sym, atr_sample = get_ecg(file)\n",
    "        \n",
    "        # grab the first signal\n",
    "        p_signal = p_signal[:,0]\n",
    "        \n",
    "        # make df to exclude the nonbeats\n",
    "        df_ann = pd.DataFrame({'atr_sym':atr_sym, 'atr_sample':atr_sample})\n",
    "        df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + ['N'])]\n",
    "        \n",
    "        X,Y,sym = build_XY(p_signal, df_ann, num_cols)\n",
    "        sym_all = sym_all+sym\n",
    "        max_rows.append(X.shape[0])\n",
    "        X_all = np.append(X_all,X,axis = 0)\n",
    "        Y_all = np.append(Y_all,Y,axis = 0)\n",
    "        \n",
    "    # drop the first zero row\n",
    "    X_all = X_all[1:]\n",
    "    Y_all = Y_all[1:]\n",
    "\n",
    "    return X_all, Y_all, sym_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066739d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_all, Y_all, sym_all = make_dataset(record_list, num_sec, fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affd244c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, Y_all, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a672ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu for activation function and drop out for regularization\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a9234af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2234/2234 [==============================] - 15s 4ms/step - loss: 0.2474 - accuracy: 0.9086\n",
      "Epoch 2/10\n",
      "2234/2234 [==============================] - 9s 4ms/step - loss: 0.1636 - accuracy: 0.9481\n",
      "Epoch 3/10\n",
      "2234/2234 [==============================] - 9s 4ms/step - loss: 0.1419 - accuracy: 0.9549\n",
      "Epoch 4/10\n",
      "2234/2234 [==============================] - 11s 5ms/step - loss: 0.1307 - accuracy: 0.9591\n",
      "Epoch 5/10\n",
      "2234/2234 [==============================] - 8s 4ms/step - loss: 0.1248 - accuracy: 0.9614\n",
      "Epoch 6/10\n",
      "2234/2234 [==============================] - 9s 4ms/step - loss: 0.1175 - accuracy: 0.9632\n",
      "Epoch 7/10\n",
      "2234/2234 [==============================] - 8s 4ms/step - loss: 0.1127 - accuracy: 0.9649\n",
      "Epoch 8/10\n",
      "2234/2234 [==============================] - 8s 3ms/step - loss: 0.1076 - accuracy: 0.9667\n",
      "Epoch 9/10\n",
      "2234/2234 [==============================] - 8s 3ms/step - loss: 0.1057 - accuracy: 0.9669\n",
      "Epoch 10/10\n",
      "2234/2234 [==============================] - 9s 4ms/step - loss: 0.1014 - accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b3a016a280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 32, epochs= 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7be9a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db9d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2234/2234 [==============================] - 63s 24ms/step\n",
      "1101/1101 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e86ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train Data\n",
      "Accuracy:0.978\n",
      "Precision:0.979\n",
      " \n",
      "On Valid Data\n",
      "Accuracy:0.970\n",
      "Precision:0.966\n",
      " \n",
      "(71485, 2160)\n"
     ]
    }
   ],
   "source": [
    "def print_report(y_actual, y_pred, thresh):\n",
    "    # Function to print evaluation metrics\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    print('Accuracy:%.3f'%accuracy)\n",
    "    print('Precision:%.3f'%precision)\n",
    "    print(' ')\n",
    "    return accuracy, precision\n",
    "\n",
    "y_train_pred = model.predict(X_train,verbose = 1)\n",
    "y_valid_pred = model.predict(X_valid,verbose = 1)\n",
    "\n",
    "thresh = (sum(y_train)/len(y_train))[0]\n",
    "\n",
    "# Accessing Evaluation Metrics Function\n",
    "print('On Train Data')\n",
    "print_report(y_train, y_train_pred, thresh)\n",
    "print('On Valid Data')\n",
    "print_report(y_valid, y_valid_pred, thresh)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ea38c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_list = []\n",
    "# idx = []\n",
    "\n",
    "# test_list.append('116')\n",
    "\n",
    "# x, y, s = make_dataset(test_list, 3, 360)\n",
    "\n",
    "# for i in range(len(y)):\n",
    "#     if y[i]==0: idx.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71cff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = model.predict(x[idx])\n",
    "\n",
    "# for i in range(len(arr)):\n",
    "#     if(arr[i]>=0.5):\n",
    "#         arr[i] = int(1)\n",
    "#     else:\n",
    "#         arr[i] = int(0)\n",
    "\n",
    "# n = y[idx]\n",
    "\n",
    "# c = 0\n",
    "# j = \n",
    "# for i in range(len(arr)):\n",
    "#     n[i] = int(n[i])\n",
    "#     if arr[i]==n[i]: c += 1\n",
    "\n",
    "# print(c)\n",
    "# print(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3574a64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fae872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
