{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135ed60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25243563, -0.1862904 , -0.39182564, ..., -0.0388762 ,\n",
       "        -0.10048325, -0.31177791],\n",
       "       [-0.14630885, -0.17047004, -0.38461413, ..., -0.6614262 ,\n",
       "        -0.25237352, -0.07386656],\n",
       "       [-1.22747546, -1.23834392, -0.89663169, ..., -1.39383795,\n",
       "        -1.50323456, -1.39152938],\n",
       "       ...,\n",
       "       [-0.133043  ,  0.27249986,  0.35817191, ..., -0.99101149,\n",
       "        -1.36921373, -1.58368854],\n",
       "       [ 0.2251349 , -0.32867358,  0.47355615, ...,  0.76677673,\n",
       "        -0.50254572,  0.40195612],\n",
       "       [-0.48458797, -0.46314659, -0.21153777, ...,  0.66607011,\n",
       "         0.48027366,  0.5483631 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "F1Score: 0.7272727272727274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import pywt\n",
    "import biosppy\n",
    "\n",
    "def bandpassFilter(data):\n",
    "    nyq = 0.5 * 500\n",
    "    low = 3 / nyq\n",
    "    high = 12 / nyq\n",
    "    b, a = signal.butter(3, [low, high], btype='band')\n",
    "    filtered_data = signal.filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def pan_tompkins(ecg_data, fs=500, rel_amplitude=0.5, min_rr=120, max_rr=200):\n",
    "    diff_data = np.diff(ecg_data)\n",
    "    squared_data = diff_data**2\n",
    "    window_size = int(0.02 * fs)\n",
    "    average_data = np.convolve(squared_data, np.ones(window_size) / window_size, mode='same')\n",
    "    high_threshold = rel_amplitude * np.max(average_data)\n",
    "    low_threshold = 0.5 * high_threshold\n",
    "    peaks = []\n",
    "    for i in range(len(ecg_data)):\n",
    "        if average_data[i] > high_threshold:\n",
    "            peaks.append(i)\n",
    "        if len(peaks) > 1 and i - peaks[-2] < min_rr:\n",
    "            peaks.pop()\n",
    "        elif len(peaks) > 2 and i - peaks[-1] > max_rr:\n",
    "            peaks.pop()\n",
    "\n",
    "    return np.array(peaks)\n",
    "\n",
    "\n",
    "def preProcessing(fileName):\n",
    "    \n",
    "    with open(fileName, 'rb') as file:\n",
    "        data = np.fromfile(file, dtype='int16')\n",
    "\n",
    "    #correcting the baseline of the data\n",
    "\n",
    "    corrected_data = signal.detrend(data)\n",
    "\n",
    "    # creating a butter-worth filter or 2nd order\n",
    "    # these are the best frequencie for this data\n",
    "\n",
    "    cutoff_freq = 10\n",
    "    sample_freq = 500 #Hz\n",
    "\n",
    "    b, a = signal.butter(2, cutoff_freq / (sample_freq / 2))\n",
    "\n",
    "    #filtering the signal\n",
    "\n",
    "    filtered_data = signal.filtfilt(b, a, corrected_data)\n",
    "\n",
    "    # applying wavelet transform on the baseline corrected data and then ignoring the high frequency and low frequency components\n",
    "    arr = pywt.wavedec(corrected_data, 'sym4', level=4)\n",
    "\n",
    "    # arr[0] = np.zeros_like(arr[0])\n",
    "    arr[1] = np.zeros_like(arr[1])\n",
    "    # arr[2] = np.zeros_like(arr[2])\n",
    "    # arr[3] = np.zeros_like(arr[3])\n",
    "    arr[4] = np.zeros_like(arr[4])\n",
    "\n",
    "    wavdec_filtered_signal = pywt.waverec(arr, 'sym4')\n",
    "\n",
    "    final_signal = bandpassFilter(wavdec_filtered_signal)\n",
    "\n",
    "    results = biosppy.signals.ecg.christov_segmenter(signal=final_signal, sampling_rate=500)\n",
    "\n",
    "    rTemp = results['rpeaks']\n",
    "    \n",
    "    r_peaks = [rTemp[0]]\n",
    "    \n",
    "    i = 1\n",
    "    while i<len(rTemp):\n",
    "        if rTemp[i]-300>rTemp[i-1]:\n",
    "            r_peaks.append(rTemp[i])\n",
    "        i += 1\n",
    "        \n",
    "    r_interval = [0]*(len(r_peaks)-1)\n",
    "\n",
    "    for i in range(1, len(r_peaks)):\n",
    "        r_interval[i-1] = r_peaks[i] - r_peaks[i-1]\n",
    "        \n",
    "    \n",
    "    return r_interval\n",
    "\n",
    "\n",
    "\n",
    "def getDataFrame(filename):\n",
    "\n",
    "    r_interval = preProcessing(filename)\n",
    "    \n",
    "    df = pd.DataFrame(columns=[f'x{i}' for i in range(15)])\n",
    "    df.loc[len(df)] = r_interval[:15]\n",
    "    return df\n",
    "\n",
    "\n",
    "def trainModel():\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('final_dataframe_cpy.csv')\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Print the shuffled DataFrame\n",
    "#     display(df.head())\n",
    "    \n",
    "    # Split the data into features (X) and labels (y)\n",
    "    X = df.drop('y', axis=1)\n",
    "    y = df['y']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    display(X_train)\n",
    "\n",
    "    # Train different classifier like logistic regression, random forest, decision tree classifier so on using sk learn ml model APIs\n",
    "\n",
    "#     model = LogisticRegression()\n",
    "#     model = DecisionTreeClassifier()\n",
    "#     model = GradientBoostingClassifier()\n",
    "#     model = KNeighborsClassifier()\n",
    "#     model = LGBMClassifier()\n",
    "#     model = XGBClassifier()\n",
    "    model = SGDClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    # for classification we use accuracy and F1 score\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1SCore = f1_score(y_test, y_pred)\n",
    "\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('F1Score:', f1SCore)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    model = trainModel()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "      # plotting bradiacardia\n",
    "\n",
    "      # plt.figure(figsize=(13, 3))\n",
    "      # plt.plot(arr1[0])\n",
    "      # plt.title(\"Bradycardia\")\n",
    "      # plt.xlabel('samples')\n",
    "      # plt.ylabel('amplitude')\n",
    "      # plt.scatter(arr1[1], arr1[0][arr1[1]], c='red')\n",
    "      # plt.grid(True)\n",
    "      # plt.ylim([-50, 150])\n",
    "      # plt.tight_layout()\n",
    "\n",
    "      # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b7d3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# print(model.predict(getDataFrame(\"tachycardia.dat\").values))\n",
    "\n",
    "print(model.predict(getDataFrame(\"normal.dat\").values))\n",
    "\n",
    "print(model.predict(getDataFrame(\"tachycardia.dat\").values))\n",
    "\n",
    "# for i in range(1, 41):\n",
    "#     filename = \"Abnormal/\"+str(i)+\".dat\"\n",
    "#     print(model.predict(getDataFrame(filename).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21a734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff0487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
